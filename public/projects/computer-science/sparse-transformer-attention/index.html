
<!DOCTYPE html>
<html lang="en">
    
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=56762&amp;path=livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Sparse Transformer Attention and Visual Image Transformer Segmentation</title>
  
  <meta name="description" content="Graduate student specializing in Mathematics and Computer Science with extensive research experience.">
  

  
  
  
  
  <link rel="stylesheet" href="/css/custom.css">
</head>

<body>
    <header class="site-header" style="background-image: url('');">
    <div class="wrapper">
        <h1 class="site-title">Yi Yao Tan</h1>
        
    </div>
</header>

    <main class="content">
        <p>My most significant project, through a five-month research internship during my undergraduate at Huawei, I created routines for sparse attention in Transformers and tested their efficiencies on NLP data sets BERT model and image classification and segmentation on ImageNet-1k (100GB) with the Visual Image Transformer Segmenter. Created data pipelines, and evaluation metrics, worked on model design, started the transformer image segmentation library for Huawei, and trained models on Huaweiâ€™s Atlas 800 HPC clusters using the newly developed, parallelization-first ML framework MindSpore.</p>
<ul>
<li><a href="https://drive.google.com/file/d/17GK_U6A_BJJWpe7aI4YoQmDiVWY2DfW9/view?usp=sharing">Manuscript</a></li>
</ul>

    </main>
    <footer id="footer">
    <p>&copy; 2024 Yi Yao Tan. All rights reserved.</p>
</footer>

</body>
</html>
