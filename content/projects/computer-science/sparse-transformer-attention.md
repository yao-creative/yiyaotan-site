---
title: "Sparse Transformer Attention and Visual Image Transformer Segmentation"
date: 2023-03-01T00:00:00+01:00
---

[Computer Science Projects](/projects/computer-science/) 

My most significant project, through a five-month research internship during my undergraduate at Huawei, I created routines for sparse attention in Transformers and tested their efficiencies on NLP data sets BERT model and image classification and segmentation on ImageNet-1k (100GB) with the Visual Image Transformer Segmenter. Created data pipelines, and evaluation metrics, worked on model design, started the transformer image segmentation library for Huawei, and trained models on Huaweiâ€™s Atlas 800 HPC clusters using the newly developed, parallelization-first ML framework MindSpore.

- [Manuscript](https://drive.google.com/file/d/17GK_U6A_BJJWpe7aI4YoQmDiVWY2DfW9/view?usp=sharing)
